{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b966a78-93d7-4d7a-8e1b-cbc79caf7d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import shape, GeometryCollection, Point, Polygon\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import openslide\n",
    "import cv2\n",
    "from pathpretrain import load_image\n",
    "import geojson\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import scanpy as sc\n",
    "import torch\n",
    "from torch_geometric.nn.pool import voxel_grid\n",
    "import plotly.graph_objects as go\n",
    "import anndata as ad\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "from scipy import stats\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.metrics import fowlkes_mallows_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d975620-0ffc-4a4c-9b47-a241860aa75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coarsen(full_xys, full_exp, size):\n",
    "    voxels=voxel_grid(torch.from_numpy(full_xys),size=(size,size))\n",
    "    coarse_xys=[]\n",
    "    coarse_exp=[]\n",
    "    central_point_indices=[]\n",
    "    for i in set(voxels.tolist()):\n",
    "        indices = torch.nonzero(voxels == i, as_tuple=False)\n",
    "        xys=torch.from_numpy(full_xys[indices]).reshape((-1,2))\n",
    "        centroid = xys.mean(dim=0)\n",
    "        distances = torch.norm(xys - centroid, dim=1)\n",
    "        most_central_point_index = torch.argmin(distances)\n",
    "        most_central_point = xys[most_central_point_index]\n",
    "        exps = torch.from_numpy(full_exp[indices]).reshape((-1,1000))\n",
    "        mean_exp = exps.mean(dim=0)\n",
    "        coarse_exp.append(mean_exp.numpy().reshape((1,1000)))\n",
    "        coarse_xys.append(most_central_point.numpy().reshape((1,2)))\n",
    "        keep_index = indices[most_central_point_index]\n",
    "        central_point_indices.append(keep_index)\n",
    "    return coarse_xys, coarse_exp, central_point_indices\n",
    "def load(patient_id, size):\n",
    "    warped=pickle.load(open(PATH_TO_WARPED_XYS,'rb'))\n",
    "    #print(warped)\n",
    "    mappings_path=PATH_TO_SECTION2PATIENT_MAPPING_TXT\n",
    "    adata_path=PATH_TO_INFERRED_ST_ANNDATA_SAVED\n",
    "    metadata_path=PATH_TO_METADATA\n",
    "    mappings=pd.read_csv(mappings_path)\n",
    "    slides=list(mappings[mappings['deident']==patient_id]['image_name'].values)\n",
    "    layers=list(mappings[mappings['deident']==patient_id]['layer'].values)\n",
    "    sorted_slides=[x for _, x in sorted(zip(layers, slides))]\n",
    "    slides=sorted_slides\n",
    "    #print(slides, sorted_slides, layers)\n",
    "    slides = [s.replace('svs','h5ad') for s in slides]\n",
    "    all_xys=[]\n",
    "    all_colors=[]\n",
    "    adatas=[]\n",
    "    print(sorted(layers))\n",
    "    for i in range(len(slides)):\n",
    "        xys=warped[slides[i]]\n",
    "        z = np.array([i for q in range(len(xys))])\n",
    "        z=z.reshape((-1,1))\n",
    "        #xys = np.concatenate([xys,z],axis=1)\n",
    "        adata = sc.read(adata_path+slides[i])\n",
    "        exp = adata.X\n",
    "        coarse_xys, coarse_exp, keep_indices= coarsen(xys, exp, size)\n",
    "        keep_indices=[t.item() for t in keep_indices]\n",
    "        #print(keep_indices)\n",
    "        sample_id=adata.obs['sample'].iloc[0]\n",
    "        metadata=pd.read_csv(metadata_path+sample_id+'_metadata.csv')\n",
    "        array_row=list(metadata['array_row'])\n",
    "        #print(array_row)\n",
    "        array_col=list(metadata['array_column'])\n",
    "        #print(adata.obsm['spatial'].shape, keep_indices[:50])\n",
    "        new_adata = ad.AnnData(X=adata.X[keep_indices], \n",
    "                               obs={'array_col':np.array(array_col)[keep_indices], 'array_row':np.array(array_row)[keep_indices]},\n",
    "                               obsm={'spatial':adata.obsm['spatial'][keep_indices]},\n",
    "                               uns={'spatial':adata.uns['spatial']})\n",
    "        new_adata.var.index = adata.var.index\n",
    "        adatas.append(new_adata)\n",
    "    return adatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1694bb4b-9d18-4ef5-8ea4-4a1455ff4d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CH SCORING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ea6bed-1fab-4452-b4c3-f392763f8cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def domains_3d_stitch(patient, resolution, voxel_size):\n",
    "    saved_dir=OUTPUTS_OF_STITCH3D\n",
    "    items=OUTPUT_OF_STITCH_3D_FOR_THIS_PATIENT\n",
    "    adatas = sorted([item for item in items if 'adata' in item])\n",
    "    adatas = [sc.read_h5ad(saved_dir+i) for i in adatas]\n",
    "    print(saved_dir)\n",
    "    for i in range(len(adatas)):\n",
    "        adatas[i].obs['section_id']=i\n",
    "    adatas=ad.concat(adatas)\n",
    "    latent = pd.read_csv(saved_dir+'/representation.csv', index_col=0)\n",
    "    adata_all = adatas[latent.index]\n",
    "    adata_all.obsm['latent'] = np.array(latent.values)\n",
    "    sc.pp.neighbors(adata_all, use_rep='latent', n_neighbors=30)\n",
    "    sc.tl.umap(adata_all)\n",
    "    sc.tl.leiden(adata_all, resolution=resolution)\n",
    "    return adata_all\n",
    "\n",
    "def domains_top_slice_norm(patient, resolution, voxel_size):\n",
    "    adata_path=PATH_TO_NORMAL_ST_SAVED_ANNDATA\n",
    "    adata_st_list_raw=load(patient, voxel_size)\n",
    "    raw_2d = adata_st_list_raw[0]\n",
    "    sc.pp.neighbors(raw_2d, n_neighbors=30, use_rep='X')\n",
    "    sc.tl.umap(raw_2d)\n",
    "    sc.tl.leiden(raw_2d, resolution=resolution)\n",
    "    domains=list(raw_2d.obs['leiden'])\n",
    "    return raw_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeba758d-e7b4-46f4-86c1-6f688dde1b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate CH scores\n",
    "def run_analysis_ch():\n",
    "    patients=PATIENT_IDS\n",
    "    resolutions_test=[0.05, 0.15, 0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85, 0.95]\n",
    "    full_avgs=[]\n",
    "    raw_avgs=[]\n",
    "    for resolution in resolutions_test:\n",
    "        full_scores=[]\n",
    "        raw_scores=[]\n",
    "        single_3d_domains=[]\n",
    "        for patient in patients:\n",
    "            voxel_size=1500\n",
    "            full= domains_3d_stitch(patient, resolution, voxel_size)\n",
    "            full_clusters=[int(v) for v in list(full.obs['leiden'])]\n",
    "            full_x = full.obsm['latent']\n",
    "            raw=domains_top_slice_norm(patient, resolution, voxel_size)\n",
    "            raw_clusters=[int(v) for v in list(raw.obs['leiden'])]\n",
    "            raw_x = raw.X\n",
    "            full_score=calinski_harabasz_score(full_x, full_clusters)\n",
    "            raw_score=calinski_harabasz_score(raw_x, raw_clusters)\n",
    "            full_scores.append(full_score)\n",
    "            raw_scores.append(raw_score)\n",
    "        print(sum(full_scores)/len(full_scores))\n",
    "        print(sum(raw_scores)/len(raw_scores))\n",
    "        print('')\n",
    "        full_avgs.append(sum(full_scores)/len(full_scores))\n",
    "        raw_avgs.append(sum(raw_scores)/len(raw_scores))\n",
    "    return full_avgs, raw_avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d093bbca-e77a-43f5-9ab7-17c0c8a33b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FM SCORING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0337164e-ffec-4ca8-9a83-8cfa0d351d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def domains_two5_stitch(patient, resolution, voxel_size):\n",
    "    #Using leiden clustering\n",
    "    # Return: considering all 3D, and just top slice\n",
    "    saved_dir=OUTPUTS_OF_STITCH3D\n",
    "    items=OUTPUT_OF_STITCH_3D_FOR_THIS_PATIENT\n",
    "    adatas = sorted([item for item in items if 'adata' in item])\n",
    "    adatas = [sc.read_h5ad(saved_dir+i) for i in adatas]\n",
    "    adatas_list=[item for item in adatas]\n",
    "    print(saved_dir)\n",
    "    for i in range(len(adatas)):\n",
    "        adatas[i].obs['section_id']=i\n",
    "    latent = pd.read_csv(saved_dir+'/representation.csv', index_col=0)\n",
    "    select_slice=0\n",
    "    print('slice'+str(select_slice))\n",
    "    index = [item for item in latent.index if 'slice'+str(select_slice) in item]\n",
    "    latent_indexed = latent[latent.index.isin(index)]\n",
    "    adata_top=adatas[latent_indexed.index]\n",
    "    adata_top.obsm['latent'] = np.array(latent_indexed.values)\n",
    "    sc.pp.neighbors(adata_top, use_rep='latent', n_neighbors=30)\n",
    "    sc.tl.umap(adata_top)\n",
    "    sc.tl.leiden(adata_top, resolution=resolution)\n",
    "    #return set(domains), set(adata_top_domains)\n",
    "    return adata_top\n",
    "def gen_annot_labels(patient_id, size):\n",
    "    warped=pickle.load(open(PATH_TO_WARPED_XYS,'rb'))\n",
    "    #print(warped)\n",
    "    mappings_path=PATH_TO_SECTION2PATIENT_MAPPING_TXT\n",
    "    adata_path=PATH_TO_INFERRED_ST_ANNDATA_SAVED\n",
    "    metadata_path=PATH_TO_METADATA\n",
    "    annots_base_path='../outs/warped_annots/'\n",
    "    mappings=pd.read_csv(mappings_path)\n",
    "    slides=list(mappings[mappings['deident']==patient_id]['image_name'].values)\n",
    "    layers=list(mappings[mappings['deident']==patient_id]['layer'].values)\n",
    "    sorted_slides=[x for _, x in sorted(zip(layers, slides))]\n",
    "    slides=sorted_slides\n",
    "    slides = [s.replace('svs','h5ad') for s in slides]\n",
    "    all_xys=[]\n",
    "    all_colors=[]\n",
    "    adatas=[]\n",
    "    print(sorted(layers))\n",
    "    all_x=[]\n",
    "    all_y=[]\n",
    "    all_z=[]\n",
    "    for i in range(len(slides)):\n",
    "        xys=warped[slides[i]]\n",
    "        print(slides)\n",
    "        z = np.array([i for q in range(len(xys))])\n",
    "        adata = sc.read(adata_path+slides[i])\n",
    "        exp = adata.X\n",
    "        coarse_xys, coarse_exp, keep_indices= coarsen(xys, exp, size)\n",
    "        xs=np.array(coarse_xys).reshape((-1,2))[:,0]\n",
    "        ys=np.array(coarse_xys).reshape((-1,2))[:,1]\n",
    "        zs=[i for q in range(len(coarse_xys))]\n",
    "        all_x+=xs.tolist();all_y+=ys.tolist();all_z+=zs\n",
    "        annots = get_annots_xys(coarse_xys, annots_base_path+slides[i].replace('h5ad','geojson'))\n",
    "        all_colors+=annots\n",
    "        keep_indices=[t.item() for t in keep_indices]\n",
    "        sample_id=adata.obs['sample'].iloc[0]\n",
    "        metadata=pd.read_csv(metadata_path+sample_id+'_metadata.csv')\n",
    "        array_row=list(metadata['array_row'])\n",
    "        array_col=list(metadata['array_column'])\n",
    "    return all_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d592ebc5-5b29-445d-ba63-b0d8197914c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run for FM scoring\n",
    "def run_analysis_fm():\n",
    "    patients=PATIENT_IDS\n",
    "    resolutions_test=RESOLUTIONS_TO_TEST\n",
    "    raw_avgs=[]\n",
    "    single_avgs=[]\n",
    "    for resolution in resolutions_test:\n",
    "        full_scores=[]\n",
    "        single_scores=[]\n",
    "        raw_scores=[]\n",
    "        single_3d_domains=[]\n",
    "        for patient in patients[1:]:\n",
    "            voxel_size=1500\n",
    "            single_3d= domains_two5_stitch(patient, resolution, voxel_size)\n",
    "            single_clusters=[int(v) for v in list(single_3d.obs['leiden'])]\n",
    "            single_x = single_3d.obsm['latent']\n",
    "            raw=domains_top_slice_norm(patient, resolution, voxel_size)\n",
    "            raw_clusters=[int(v) for v in list(raw.obs['leiden'])]\n",
    "            raw_x = raw.X\n",
    "            annots_true = gen_annot_labels(patient,voxel_size)\n",
    "            \n",
    "            single_score=fowlkes_mallows_score(annots_true, single_clusters)\n",
    "            raw_scores.append(raw_score)\n",
    "            single_scores.append(single_score)\n",
    "            print(single_score, raw_score)\n",
    "        print(sum(single_scores)/len(single_scores))\n",
    "        print(sum(raw_scores)/len(raw_scores))\n",
    "        print('')\n",
    "        raw_avgs.append(sum(raw_scores)/len(raw_scores))\n",
    "        single_avgs.append(sum(single_scores)/len(single_scores))\n",
    "    return full_avgs, raw_avgs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
